{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05e4b15-f811-4cc1-9e65-62dd5cccca5a",
   "metadata": {},
   "source": [
    "# AUTHORITATIVE VERSION AS OF 2023/09/14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87211d7e-8034-499f-aeaf-a7c4d9205d9c",
   "metadata": {},
   "source": [
    "This notebook fits the NP params to Zea lettuce data\n",
    "* mN and YN are constrained to empirical values\n",
    "* hybrid MEC-NP model plot is generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbce650-aa5b-49bd-8ab1-a17df8beda79",
   "metadata": {},
   "source": [
    "## Import libraries and globally set parameters for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24361ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "from DU4 import *\n",
    "import time\n",
    "\n",
    "import matplotlib.style as style\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "style.use('seaborn-poster')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "'''\n",
    "Spines & lines\n",
    "'''\n",
    "box_lw = 1\n",
    "mono_colr = 'k'\n",
    "plt.rcParams['axes.spines.bottom'] = True\n",
    "plt.rcParams['axes.spines.left'] = True\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.linewidth'] = box_lw\n",
    "plt.rcParams['xtick.major.width'] = box_lw\n",
    "plt.rcParams['ytick.major.width'] = box_lw\n",
    "'''\n",
    "Fonts & size\n",
    "'''\n",
    "plt_font_size = 8\n",
    "lgd_font_size = 5\n",
    "plt.rcParams['font.family'] = \"TeX Gyre Termes\"\n",
    "#plt.rc('font', **{'family' : 'sans-serif', 'sans-serif' : ['Myriad Pro']})\n",
    "plt.rcParams['font.size'] = plt_font_size\n",
    "plt.rcParams['axes.labelsize'] = plt_font_size\n",
    "plt.rcParams['axes.titlesize'] = plt_font_size\n",
    "plt.rcParams['xtick.labelsize'] = plt_font_size\n",
    "plt.rcParams['ytick.labelsize'] = plt_font_size\n",
    "plt.rcParams['xtick.major.pad'] = 2\n",
    "plt.rcParams['ytick.major.pad'] = 2\n",
    "plt.rcParams['legend.fontsize'] = lgd_font_size\n",
    "'''\n",
    "Plots\n",
    "'''\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['lines.markeredgewidth'] = 3\n",
    "plt.rcParams['errorbar.capsize'] = 5\n",
    "plt.rcParams['lines.markersize'] = 4\n",
    "'''\n",
    "Colours\n",
    "'''\n",
    "plt.rcParams['axes.titlecolor'] = mono_colr\n",
    "plt.rcParams['axes.edgecolor'] = mono_colr\n",
    "plt.rcParams['axes.labelcolor'] = mono_colr\n",
    "plt.rcParams['xtick.color'] = mono_colr\n",
    "plt.rcParams['xtick.labelcolor'] = mono_colr\n",
    "plt.rcParams['ytick.color'] = mono_colr\n",
    "plt.rcParams['ytick.labelcolor'] = mono_colr\n",
    "'''\n",
    "LaTeX\n",
    "'''\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['text.latex.preamble'] = '\\n'.join([\n",
    "    r'\\usepackage[T3,T1]{fontenc}',\n",
    "    r'\\DeclareSymbolFont{tipa}{T3}{cmr}{m}{n}',\n",
    "    r'\\DeclareMathAccent{\\invbreve}{\\mathalpha}{tipa}{16}',\n",
    "    r'\\usepackage{siunitx}',\n",
    "    r'\\DeclareSIUnit\\crewmember{CM}',\n",
    "    r'\\sisetup{range-units=single}',\n",
    "    r'\\sisetup{range-phrase=\\textup{--}}'\n",
    "])  # Preamble must be one line!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39da259-f9c7-4d12-b925-0351054ad620",
   "metadata": {},
   "source": [
    "## Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347bd9e0-2cc9-4e23-9c4a-3650ae4dc111",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_color=\"MidnightBlue\"\n",
    "md_color=\"DodgerBlue\"\n",
    "lw_color=\"SkyBlue\"\n",
    "np_color=\"k\"\n",
    "\n",
    "out_path = \"./NP-fits/\"\n",
    "mat_out_path = \"./sens-mat/\"\n",
    "\n",
    "c_CO2 = 525\n",
    "Phi_gamma = 225\n",
    "sigma_N = 19.2 # planting density\n",
    "f_E = 1 # we look at the whole plant, not just edible part\n",
    "endtime = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b83dac7-ac4d-4e93-93f4-a48cdda7dc9e",
   "metadata": {},
   "source": [
    "## Define functions for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models_less(params, exp_times=None):\n",
    "    \n",
    "    #print(params.shape)\n",
    "    def calc_eta_u(t, crop, c_CO2, Phi_gamma):\n",
    "        '''\n",
    "        N uptake performance, 1 = max\n",
    "        Could account for things like temp, pH\n",
    "        Assume max for now\n",
    "        Dimensionless\n",
    "        '''\n",
    "        return 1\n",
    "\n",
    "    def calc_mu_N(t, crop, c_CO2, Phi_gamma):\n",
    "        '''\n",
    "        seems to decrease over time\n",
    "        needs to depend on c_N where high or low c_N limits mu_N\n",
    "        could measure by mu_N = [ln(m_N(t2)) - ln(m_N(t1))] / (t2 - t1)\n",
    "        linear fit from Normal N\n",
    "        units of day^-1\n",
    "        '''\n",
    "        mu_N = -params[6] * t + params[5]\n",
    "        return mu_N\n",
    "\n",
    "    def calc_eta_N(t, crop, c_CO2, Phi_gamma):\n",
    "        '''\n",
    "        amount of plant you get per amount of N over time step\n",
    "        eta_N = m_B / <m_N>\n",
    "        dimensionless, but g_DW / g_N\n",
    "        '''\n",
    "        eta_N = -params[4]*t + params[3] \n",
    "        return eta_N\n",
    "\n",
    "    def calc_m_N(t, crop, c_CO2, Phi_gamma):\n",
    "        '''\n",
    "        m_N0 unit: g\n",
    "        K unit: g\n",
    "        r unit: day^-1\n",
    "        m_N unit: g\n",
    "        '''\n",
    "        m_N0 = 5.1e-3  #Got it from fitting with MEC, estimate from data using N percentage in biomass\n",
    "        r = params[0]\n",
    "        K = params[1]\n",
    "        alpha = params[2]\n",
    "        m_N = alpha * (m_N0 * K * np.exp(r * t)) / ((K - m_N0) + m_N0 * np.exp(r * t))\n",
    "        return m_N\n",
    "\n",
    "    def calc_Y_N(t, crop, c_CO2, Phi_gamma):\n",
    "        '''\n",
    "        Calculated value is too high vs. empirical data - should be ~2 from day 23-37\n",
    "        Seems to be because eta_N is too high early on\n",
    "        '''\n",
    "        Y_N = calc_eta_u(t, crop, c_CO2, Phi_gamma) * calc_mu_N(t, crop, c_CO2, Phi_gamma) * calc_eta_N(t, crop, c_CO2, Phi_gamma)\n",
    "        return Y_N\n",
    "\n",
    "    def calc_m_B_NP(t, crop, c_CO2, Phi_gamma):\n",
    "        return calc_Y_N(t,crop,c_CO2,Phi_gamma) * calc_m_N(t,crop,c_CO2,Phi_gamma)\n",
    "\n",
    "    def NP_model(t, y, crop, c_CO2, Phi_gamma):\n",
    "        Neq = len(y)\n",
    "\n",
    "        ## Prepare dydt array\n",
    "        dydt = np.zeros((1, Neq))\n",
    "\n",
    "        ## Define dydt\n",
    "        dydt[0, 0] = calc_m_B_NP(t, crop, c_CO2, Phi_gamma)\n",
    "\n",
    "        return [np.transpose(dydt)]\n",
    "\n",
    "    # for all models\n",
    "    tspan = [0, endtime]\n",
    "    if len(exp_times) == 0:\n",
    "        t_eval = np.arange(0, endtime+1, 1) #Where do we want the solution\n",
    "    else:\n",
    "        t_eval = exp_times.reshape(-1,)\n",
    "    y0 = [0,0,50]\n",
    "\n",
    "    sol_NP = integrate.solve_ivp(NP_model, tspan, y0, args=(\"lettuce\",c_CO2,Phi_gamma), method='LSODA', t_eval=t_eval)\n",
    "    sol_NP.y[0] = sol_NP.y[0] * sigma_N * f_E\n",
    "\n",
    "    # fig, ax1 = plt.subplots(1, figsize=(5, 5))\n",
    "    # plt.ylim(0,120)\n",
    "    # plt.plot(sol_NP.t, sol_NP.y[0],linewidth=4, color = 'blue', label=\"NP normal\")\n",
    "    # plt.ylabel('Edible Biomass $[\\si{\\gram\\of{DW}\\per\\meter\\squared}]$')\n",
    "    # plt.xlabel('Time, t [d$_{\\mathrm{AE}}$]')\n",
    "    # plt.title('NP Model of Biomass Growth')\n",
    "\n",
    "    # Put MEC on top of it\n",
    "    def mec_model(t, y, crop, CO2, PPF):\n",
    "        Neq = len(y)\n",
    "\n",
    "        ## Prepare dydt array\n",
    "        dydt = np.zeros((1, Neq))\n",
    "\n",
    "        ## Define dydt\n",
    "        dydt[0, 0] = calc_m_B(t, crop, CO2, PPF)\n",
    "\n",
    "        return [np.transpose(dydt)]\n",
    "\n",
    "    ## Define directory and locations\n",
    "    directory = 'parameter-lists/'\n",
    "    filename = 'crop_parameters_FPSD.xlsx'\n",
    "\n",
    "    ## Load standard parameters from BVAD\n",
    "    filename_full = directory + filename\n",
    "\n",
    "    ## Load the standard lettuce crop\n",
    "    crop_type = 'lettuce'\n",
    "    crop = Crop(crop_type, filename_full=filename_full)\n",
    "    crop.t_M = endtime\n",
    "\n",
    "    ## Perform integration\n",
    "    start_time = time.time()\n",
    "    sol_MEC = integrate.solve_ivp(mec_model, tspan, y0, args=(crop,c_CO2,Phi_gamma), method='LSODA', t_eval=t_eval)\n",
    "   # print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    ## Convert m_T to m_E (with lettuce t_E = 0)\n",
    "    sol_MEC.y[0] *= crop.f_E\n",
    "\n",
    "    #plt.plot(sol_MEC.t, sol_MEC.y[0], linewidth=4, color = 'g', ls='--', label=\"MEC prediction\")\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    # show function values over time\n",
    "    f=np.zeros((50,1))\n",
    "    g=np.zeros((50,1))\n",
    "    h=np.zeros((50,1))\n",
    "    j=np.zeros((50,1))\n",
    "\n",
    "    for i in range(0,50):\n",
    "        f[i] = calc_mu_N(i, crop, c_CO2, Phi_gamma)\n",
    "        g[i] = calc_m_N(i, crop, c_CO2, Phi_gamma)\n",
    "        h[i] = calc_Y_N(i, crop, c_CO2, Phi_gamma)\n",
    "        j[i] = calc_eta_N(i, crop, c_CO2, Phi_gamma)\n",
    "\n",
    "    #plt.plot(np.arange(0,50), f, label=\"$\\mu_N$\")\n",
    "    #plt.plot(np.arange(0,50), g, label=\"$m_N$\")\n",
    "    #plt.plot(np.arange(0,50), h, label=\"$\\dot{Y}_N$\")\n",
    "    #plt.plot(np.arange(0,50), j, label=\"$\\eta_N$\")\n",
    "    #plt.legend()\n",
    "    # Create arrays to store m_N and Y_N values for sol_NP.t\n",
    "    m_N_values = np.zeros(len(sol_NP.t))\n",
    "    Y_N_values = np.zeros(len(sol_NP.t))\n",
    "\n",
    "    # Evaluate m_N and Y_N for each time point in sol_NP.t\n",
    "    for i, t in enumerate(sol_NP.t):\n",
    "        m_N_values[i] = calc_m_N(t, crop, c_CO2, Phi_gamma)\n",
    "        Y_N_values[i] = calc_Y_N(t, crop, c_CO2, Phi_gamma)\n",
    "\n",
    "    # Return the arrays along with the other return values\n",
    "    return sol_MEC.t, sol_MEC.y[0], sol_NP.t, sol_NP.y[0], m_N_values, Y_N_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997aea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(params, exp_times=None):\n",
    "    \n",
    "    #print(params.shape)\n",
    "    def calc_eta_u(t, crop, c_CO2, Phi_gamma):\n",
    "        '''\n",
    "        N uptake performance, 1 = max\n",
    "        Could account for things like temp, pH\n",
    "        Assume max for now\n",
    "        Dimensionless\n",
    "        '''\n",
    "        return 1\n",
    "\n",
    "    def calc_mu_N(t, crop, c_CO2, Phi_gamma):\n",
    "        '''\n",
    "        seems to decrease over time\n",
    "        needs to depend on c_N where high or low c_N limits mu_N\n",
    "        could measure by mu_N = [ln(m_N(t2)) - ln(m_N(t1))] / (t2 - t1)\n",
    "        linear fit from Normal N\n",
    "        units of day^-1\n",
    "        '''\n",
    "        mu_N = -params[7] * t + params[6]\n",
    "        return mu_N\n",
    "\n",
    "    def calc_eta_N(t, crop, c_CO2, Phi_gamma):\n",
    "        '''\n",
    "        amount of plant you get per amount of N over time step\n",
    "        eta_N = m_B / <m_N>\n",
    "        can approach zero, but should not become negative\n",
    "        *** FIX THIS ***\n",
    "        dimensionless, but g_DW / g_N\n",
    "        '''\n",
    "        eta_N = -params[5]*t + params[4] \n",
    "        return eta_N\n",
    "\n",
    "    def calc_m_N(t, crop, c_CO2, Phi_gamma):\n",
    "        '''\n",
    "        Maybe Monod-style kinetics as GM suggested\n",
    "\n",
    "        4 parameter logistic fit?\n",
    "\n",
    "        All values except m_N0 are guesses not based on data\n",
    "\n",
    "        The value of m_N is too high vs. empirical data\n",
    "            * Empirical data could be sigmoidal\n",
    "            * Maybe we call it something else\n",
    "\n",
    "        m_N0 unit: g\n",
    "        K unit: g\n",
    "        r unit: day^-1\n",
    "        m_N unit: g\n",
    "        '''\n",
    "        m_N0 = params[0]\n",
    "        r = params[1]\n",
    "        K = params[2]\n",
    "        alpha = params[3]\n",
    "        m_N = alpha * (m_N0 * K * np.exp(r * t)) / ((K - m_N0) + m_N0 * np.exp(r * t))  # huger guess\n",
    "        return m_N\n",
    "\n",
    "    def calc_Y_N(t, crop, c_CO2, Phi_gamma):\n",
    "        '''\n",
    "        Calculated value is too high vs. empirical data - should be ~2 from day 23-37\n",
    "        Seems to be because eta_N is too high early on\n",
    "        '''\n",
    "        Y_N = calc_eta_u(t, crop, c_CO2, Phi_gamma) * calc_mu_N(t, crop, c_CO2, Phi_gamma) * calc_eta_N(t, crop, c_CO2, Phi_gamma)\n",
    "        return Y_N\n",
    "\n",
    "    def calc_m_B_NP(t, crop, c_CO2, Phi_gamma):\n",
    "        return calc_Y_N(t,crop,c_CO2,Phi_gamma) * calc_m_N(t,crop,c_CO2,Phi_gamma)\n",
    "\n",
    "    def NP_model(t, y, crop, c_CO2, Phi_gamma):\n",
    "        Neq = len(y)\n",
    "\n",
    "        ## Prepare dydt array\n",
    "        dydt = np.zeros((1, Neq))\n",
    "\n",
    "        ## Define dydt\n",
    "        dydt[0, 0] = calc_m_B_NP(t, crop, c_CO2, Phi_gamma)\n",
    "\n",
    "        return [np.transpose(dydt)]\n",
    "        \n",
    "    # for all models\n",
    "    tspan = [0, endtime]\n",
    "    if len(exp_times) == 0:\n",
    "        t_eval = np.arange(0, endtime+1, 1) #Where do we want the solution\n",
    "    else:\n",
    "        t_eval = exp_times.reshape(-1,)\n",
    "    y0 = [0,0,50]\n",
    "\n",
    "    sol_NP = integrate.solve_ivp(NP_model, tspan, y0, args=(\"lettuce\",c_CO2,Phi_gamma), method='LSODA', t_eval=t_eval)\n",
    "    sol_NP.y[0] = sol_NP.y[0] * sigma_N * f_E\n",
    "\n",
    "    #fig, ax1 = plt.subplots(1, figsize=(5, 5))\n",
    "    # plt.ylim(0,120)\n",
    "    #plt.plot(sol_NP.t, sol_NP.y[0],linewidth=4, color = 'blue', label=\"NP normal\")\n",
    "    #plt.ylabel('Edible Biomass $[\\si{\\gram\\of{DW}\\per\\meter\\squared}]$')\n",
    "    #plt.xlabel('Time, t [d$_{\\mathrm{AE}}$]')\n",
    "    #plt.title('NP Model of Biomass Growth')\n",
    "\n",
    "    # Put MEC on top of it\n",
    "    def mec_model(t, y, crop, CO2, PPF):\n",
    "        Neq = len(y)\n",
    "\n",
    "        ## Prepare dydt array\n",
    "        dydt = np.zeros((1, Neq))\n",
    "\n",
    "        ## Define dydt\n",
    "        dydt[0, 0] = calc_m_B(t, crop, CO2, PPF)\n",
    "\n",
    "        return [np.transpose(dydt)]\n",
    "\n",
    "    ## Define directory and locations\n",
    "    directory = 'parameter-lists/'\n",
    "    filename = 'crop_parameters_FPSD.xlsx'\n",
    "\n",
    "    ## Load standard parameters from BVAD\n",
    "    filename_full = directory + filename\n",
    "\n",
    "    ## Load the standard lettuce crop\n",
    "    crop_type = 'lettuce'\n",
    "    crop = Crop(crop_type, filename_full=filename_full)\n",
    "    crop.t_M = endtime\n",
    "\n",
    "    ## Perform integration\n",
    "    start_time = time.time()\n",
    "    sol_MEC = integrate.solve_ivp(mec_model, tspan, y0, args=(crop,c_CO2,Phi_gamma), method='LSODA', t_eval=t_eval)\n",
    "   # print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    ## Convert m_T to m_E (with lettuce t_E = 0)\n",
    "    sol_MEC.y[0] *= crop.f_E\n",
    "\n",
    "    #plt.plot(sol_MEC.t, sol_MEC.y[0], linewidth=4, color = 'g', ls='--', label=\"MEC prediction\")\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    # show function values over time\n",
    "    f=np.zeros((50,1))\n",
    "    g=np.zeros((50,1))\n",
    "    h=np.zeros((50,1))\n",
    "    j=np.zeros((50,1))\n",
    "\n",
    "    for i in range(0,50):\n",
    "        f[i] = calc_mu_N(i, crop, c_CO2, Phi_gamma)\n",
    "        g[i] = calc_m_N(i, crop, c_CO2, Phi_gamma)\n",
    "        h[i] = calc_Y_N(i, crop, c_CO2, Phi_gamma)\n",
    "        j[i] = calc_eta_N(i, crop, c_CO2, Phi_gamma)\n",
    "    # Create arrays to store m_N and Y_N values for sol_NP.t\n",
    "    m_N_values = np.zeros(len(sol_NP.t))\n",
    "    Y_N_values = np.zeros(len(sol_NP.t))\n",
    "\n",
    "    # Evaluate m_N and Y_N for each time point in sol_NP.t\n",
    "    for i, t in enumerate(sol_NP.t):\n",
    "        m_N_values[i] = calc_m_N(t, crop, c_CO2, Phi_gamma)\n",
    "        Y_N_values[i] = calc_Y_N(t, crop, c_CO2, Phi_gamma)\n",
    "\n",
    "    # Return the arrays along with the other return values\n",
    "    return sol_MEC.t, sol_MEC.y[0], sol_NP.t, sol_NP.y[0], m_N_values, Y_N_values\n",
    "    #plt.plot(np.arange(0,50), f, label=\"$\\mu_N$\")\n",
    "    #plt.plot(np.arange(0,50), g, label=\"$m_N$\")\n",
    "    #plt.plot(np.arange(0,50), h, label=\"$\\dot{Y}_N$\")\n",
    "    #plt.plot(np.arange(0,50), j, label=\"$\\eta_N$\")\n",
    "    #plt.legend()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dfc07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(x,print_flag):\n",
    "    \"\"\"\n",
    "    Fitting function to be minimized in order to compare\n",
    "    MEC and NP\n",
    "    x:Model parameters\n",
    "    print_flag : whether to plot predictions or not\n",
    "    \"\"\"\n",
    "    t_MEC, y_MEC, t_NP, y_NP, _, _= run_models(x,[])\n",
    "    if print_flag:\n",
    "        plt.figure(dpi=300,figsize=(2,2))\n",
    "        plt.plot(t_MEC, y_MEC, label='MEC Model')\n",
    "        plt.plot(t_NP, y_NP, label='NP Model')\n",
    "        plt.legend()\n",
    "    a = y_MEC\n",
    "    b = y_NP\n",
    "    diff = np.abs(a - b) \n",
    "    norm = np.linalg.norm(diff, ord=2)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The nominal parameters - Defined by Kevin\n",
    "x_nom = np.array([0.0017, 0.225, 7,0.085,38.0, 0.95,0.7,0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ev = objective_function(x_nom,True) #evaluate the error based on nominal parameters\n",
    "print(f_ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731fcfc",
   "metadata": {},
   "source": [
    "## Define Lower/Upper Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b35216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "ls = 0.1 #Multiplier for lower bound\n",
    "us = 3.0 #Multiplier for upper bound\n",
    "x0 = [0.0017, 0.225, 7.0 ,0.085,38.0, 0.95,0.7,0.01]  # initial guess for the decision variables\n",
    "bounds = [(x0[0]*ls,x0[0]*us ), (x0[1]*ls,x0[1]*us ), ((x0[2]*ls,x0[2]*us )),\n",
    "          (x0[3]*ls,x0[3]*us ),(x0[4]*ls,x0[4]*us ),(x0[5]*ls,x0[5]*us ),\n",
    "         (x0[6]*ls,x0[6]*us ),(x0[7]*0.8,x0[7]*1.2 ) ]  # bounds on the decision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e625a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'disp': False}\n",
    "result = minimize(objective_function, x0, args=(False) , bounds=bounds,options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b91fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ev = objective_function(result.x,True) #Re-evaluate based on optimal values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673eda9",
   "metadata": {},
   "source": [
    "### Read all experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f70709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = './zea-data/'\n",
    "for filename in os.listdir(data_path):\n",
    "    if os.path.isfile(os.path.join(data_path, filename)):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6272525",
   "metadata": {},
   "source": [
    "### Normal Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(data_path + 'zea_biomass-dw-area_normal.csv')\n",
    "times  = df['dAE']\n",
    "points = df['mB mean [gDW/m^2]']\n",
    "# Convert the column to a NumPy array\n",
    "times_normal = times.values\n",
    "points_normal = points.values\n",
    "# Reshape the array to have shape (n, 1)\n",
    "times_normal =times_normal.reshape(-1, 1)\n",
    "points_normal = points_normal.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + \"zea_nitrogen-mass_normal.csv\")\n",
    "times = df['dAE'][0:6]\n",
    "points = df['mN mean [g]'][0:6]\n",
    "# Convert the column to a NumPy array\n",
    "times_N_normal = times.values\n",
    "points_N_normal = points.values\n",
    "# Reshape the array to have shape (n, 1)\n",
    "times_N_normal =times_N_normal.reshape(-1, 1)\n",
    "points_N_normal = points_N_normal.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + \"zea_YN_normal.csv\")\n",
    "times = df['dAE'][0:5]\n",
    "points = df['YN mean [g]'][0:5]\n",
    "# Convert the column to a NumPy array\n",
    "times_YN_normal = times.values\n",
    "points_YN_normal = points.values\n",
    "# Reshape the array to have shape (n, 1)\n",
    "times_YN_normal =times_YN_normal.reshape(-1, 1)\n",
    "points_YN_normal = points_YN_normal.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d565bd7",
   "metadata": {},
   "source": [
    "### Excess Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + 'zea_biomass-dw-area_excess.csv')\n",
    "times  = df['dAE']\n",
    "points = df['mB mean [gDW/m^2]']\n",
    "# Convert the column to a NumPy array\n",
    "times_excess = times.values\n",
    "points_excess = points.values\n",
    "# Reshape the array to have shape (n, 1)\n",
    "times_excess =times_excess.reshape(-1, 1)\n",
    "points_excess = points_excess.reshape(-1,1)\n",
    "\n",
    "df = pd.read_csv(data_path + \"zea_nitrogen-mass_excess.csv\")\n",
    "times = df['dAE'][0:6]\n",
    "points = df['mN mean [g]'][0:6]\n",
    "# Convert the column to a NumPy array\n",
    "times_N_excess = times.values\n",
    "points_N_excess = points.values\n",
    "# Reshape the array to have shape (n, 1)\n",
    "times_N_excess = times_N_excess.reshape(-1, 1)\n",
    "points_N_excess = points_N_excess.reshape(-1,1)\n",
    "\n",
    "df = pd.read_csv(data_path + \"zea_YN_excess.csv\")\n",
    "times = df['dAE'][0:5]\n",
    "points = df['YN mean [g]'][0:5]\n",
    "# Convert the column to a NumPy array\n",
    "times_YN_excess = times.values\n",
    "points_YN_excess = points.values\n",
    "# Reshape the array to have shape (n, 1)\n",
    "times_YN_excess = times_YN_excess.reshape(-1, 1)\n",
    "points_YN_excess = points_YN_excess.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c91f21",
   "metadata": {},
   "source": [
    "### Deficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced28034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + 'zea_biomass-dw-area_deficient.csv')\n",
    "times  = df['dAE']\n",
    "points = df['mB mean [gDW/m^2]']\n",
    "# Convert the column to a NumPy array\n",
    "times_deficient = times.values\n",
    "points_deficient = points.values\n",
    "# Reshape the array to have shape (n, 1)\n",
    "times_deficient  = times_deficient.reshape(-1, 1)\n",
    "points_deficient = points_deficient.reshape(-1,1)\n",
    "\n",
    "########################################################\n",
    "df = pd.read_csv(data_path + \"zea_nitrogen-mass_deficient.csv\")\n",
    "times = df['dAE'][0:6]\n",
    "points = df['mN mean [g]'][0:6]\n",
    "# Convert the column to a NumPy array\n",
    "times_N_deficient = times.values\n",
    "points_N_deficient = points.values\n",
    "# Reshape the array to have shape (n, 1)\n",
    "times_N_deficient = times_N_deficient.reshape(-1, 1)\n",
    "points_N_deficient = points_N_deficient.reshape(-1,1)\n",
    "##############################################################\n",
    "\n",
    "df = pd.read_csv(data_path + \"zea_YN_deficient.csv\")\n",
    "times = df['dAE'][0:5]\n",
    "points = df['YN mean [g]'][0:5]\n",
    "# Convert the column to a NumPy array\n",
    "times_YN_deficient = times.values\n",
    "points_YN_deficient = points.values\n",
    "# Reshape the array to have shape (n, 1)\n",
    "times_YN_deficient = times_YN_deficient.reshape(-1, 1)\n",
    "points_YN_deficient = points_YN_deficient.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d4ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times_normal,times_excess,times_deficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa68010",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times_N_normal,times_N_excess,times_N_deficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fa1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times_YN_normal,times_YN_excess,times_YN_deficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_normal == times_N_deficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac522e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1.5,1.5))\n",
    "plt.plot(times_normal, points_normal,'-o')\n",
    "plt.plot(times_excess, points_excess,'-o')\n",
    "plt.plot(times_deficient, points_deficient,'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1.5,1.5))\n",
    "plt.plot(times_N_normal, points_N_normal,'-o')\n",
    "plt.plot(times_N_excess, points_N_excess,'-o')\n",
    "plt.plot(times_N_deficient, points_N_deficient,'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af67e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1.5,1.5))\n",
    "plt.plot(times_YN_normal, points_YN_normal,'-o')\n",
    "plt.plot(times_YN_excess, points_YN_excess,'-o')\n",
    "plt.plot(times_YN_deficient, points_YN_deficient,'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa95c32-2780-4c85-a99e-5906402f85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_experiment(xnm, xn, xe, xd, print_flag):\n",
    "    \"\"\"\n",
    "    For plotting final predictions after fitting\n",
    "    xn: parameters for normal fit\n",
    "    xe: parameters for excess fit\n",
    "    xd: parameters for deficit fit\n",
    "    \"\"\"\n",
    "    t_eval = np.arange(0, 40, 0.5)\n",
    "    t_MECnM, y_MECnM, t_NPnM, y_NPnM, mNnm, yNnm = run_models_less(xnm[1:], t_eval)\n",
    "    \n",
    "    t_MECn, y_MECn, t_NPn, y_NPn, mNn, yNn = run_models_less(xn, t_eval)\n",
    "    t_MECe, y_MECe, t_NPe, y_NPe, mNe, yNe = run_models_less(xe, t_eval)\n",
    "    t_MECd, y_MECd, t_NPd, y_NPd, mNd, yNd = run_models_less(xd, t_eval)\n",
    "    \n",
    "    if print_flag:\n",
    "        # Plotting Biomass Concentration\n",
    "        # plt.figure(dpi=2000, figsize=(2, 2))\n",
    "        # plt.plot(t_NPnM, y_NPnM, '--', label='Normal', color=md_color)\n",
    "        # plt.plot(t_NPn, y_NPn, '-', label='Normal', color=md_color)\n",
    "        # plt.plot(t_NPe, y_NPe, '-', label='Excess', color=hg_color)\n",
    "        # plt.plot(t_NPd, y_NPd, '-', label='Deficit', color=lw_color)\n",
    "        # plt.plot(times_normal, points_normal, 'o', color=md_color)\n",
    "        # plt.plot(times_excess, points_excess, 'o', color=hg_color)\n",
    "        # plt.plot(times_deficient, points_deficient, 'o', color=lw_color)\n",
    "        # plt.xlabel('Time (hr)')\n",
    "        # plt.ylabel('Biomass Concentration')\n",
    "        # plt.legend()\n",
    "        plt.figure(figsize=(2,2), dpi=2000)\n",
    "        plt.plot(t_NPe, y_NPe, '--',label='NP Excess', color=hg_color)\n",
    "        plt.plot(t_NPn, y_NPn, '--',label='NP Normal', color=md_color)\n",
    "        plt.plot(t_NPd, y_NPd, '--',label='NP Deficient', color=lw_color)\n",
    "        plt.plot(t_NPnM, y_NPnM, '--',label='MEC', color='LimeGreen' )\n",
    "        #plt.plot(t_MEC, y_MEC, label='MEC Model', color='red')\n",
    "        plt.plot(times_normal, points_normal,'o',color=md_color)\n",
    "        plt.plot(times_excess, points_excess,'o',color=hg_color)\n",
    "        plt.plot(times_deficient, points_deficient,'o',color=lw_color)\n",
    "        # plt.xlabel(\"Time, $t\\ [\\si{\\day\\of{AE}}]$\")\n",
    "        plt.xlabel(\"$t\\ [\\si{\\day\\of{AE}}]$\")\n",
    "        # plt.ylabel(\"Areal dry weight biomass,\\n $\\invbreve{m}_\\mathrm{B}\\ [\\si{\\gram\\of{DW}\\per\\meter\\squared}]$\")\n",
    "        plt.ylabel(\"$\\invbreve{m}_\\mathrm{B}\\ [\\si{\\gram\\of{DW}\\per\\meter\\squared}]$\")\n",
    "        plt.gca().xaxis.set_major_locator(MultipleLocator(10))\n",
    "        plt.gca().xaxis.set_minor_locator(MultipleLocator(5))\n",
    "        plt.gca().yaxis.set_major_locator(MultipleLocator(20))\n",
    "        plt.gca().yaxis.set_minor_locator(MultipleLocator(10))\n",
    "        plt.legend()\n",
    "        plt.legend(ncol=1, loc=\"upper left\")#,  bbox_to_anchor=(0.5, -0.5))\n",
    "        plt.savefig(out_path + \"lettuce_all_NP-fit.png\", bbox_inches='tight', transparent=True)\n",
    "        \n",
    "        # Plotting m_N values\n",
    "        plt.figure(dpi=2000, figsize=(2,2))\n",
    "        plt.plot(t_NPe, mNe, '--', label='Excess', color=hg_color)\n",
    "        plt.plot(t_NPn, mNn, '--', label='Normal', color=md_color)\n",
    "        plt.plot(t_NPd, mNd, '--', label='Deficient', color=lw_color)\n",
    "        plt.plot(times_N_normal, points_N_normal, 'o', color=md_color)\n",
    "        plt.plot(times_N_excess, points_N_excess, 'o', color=hg_color)\n",
    "        plt.plot(times_N_deficient, points_N_deficient, 'o', color=lw_color)\n",
    "        plt.xlabel(\"Time, $t\\ [\\si{\\day\\of{AE}}]$\")\n",
    "        plt.ylabel('$m_\\mathrm{N}\\ [\\si{\\gram}]$')\n",
    "        plt.gca().xaxis.set_major_locator(MultipleLocator(10))\n",
    "        plt.gca().xaxis.set_minor_locator(MultipleLocator(5))\n",
    "        plt.gca().yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        plt.gca().yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "        plt.legend()\n",
    "        # plt.title('m_N over Time')\n",
    "        plt.savefig(out_path + \"lettuce_all_mN-fit.png\", bbox_inches='tight', transparent=True)\n",
    "        \n",
    "        # Plotting Y_N values\n",
    "        plt.figure(dpi=2000, figsize=(2,2))\n",
    "        plt.plot(t_NPe, yNe, '--', label='Excess', color=hg_color)\n",
    "        plt.plot(t_NPn, yNn, '--', label='Normal', color=md_color)\n",
    "        plt.plot(t_NPd, yNd, '--', label='Deficient', color=lw_color)\n",
    "        plt.plot(times_YN_normal, points_YN_normal, 'o', color=md_color)\n",
    "        plt.plot(times_YN_excess, points_YN_excess, 'o', color=hg_color)\n",
    "        plt.plot(times_YN_deficient, points_YN_deficient, 'o', color=lw_color)\n",
    "        plt.xlabel(\"$t\\ [\\si{\\day\\of{AE}}]$\")\n",
    "        # plt.ylabel(\"Areal dry weight biomass,\\n $\\invbreve{m}_\\mathrm{B}\\ [\\si{\\gram\\of{DW}\\per\\meter\\squared}]$\")\n",
    "        plt.ylabel(\"$\\dot{Y}_\\mathrm{N}\\ [\\si{\\gram\\of{DW}\\per\\day\\per\\gram\\of{N}}]$\")\n",
    "        plt.gca().xaxis.set_major_locator(MultipleLocator(10))\n",
    "        plt.gca().xaxis.set_minor_locator(MultipleLocator(5))\n",
    "        plt.gca().yaxis.set_major_locator(MultipleLocator(1))\n",
    "        plt.gca().yaxis.set_minor_locator(MultipleLocator(0.5))\n",
    "        plt.legend()\n",
    "        # plt.title('Y_N over Time')\n",
    "        plt.savefig(out_path + \"lettuce_all_YN-fit.png\", bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97425c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_experiment(x, print_flag, condition):\n",
    "    \n",
    "    # Extract m_N, Y_N, and biomass values from the model\n",
    "    t_MEC, y_MEC, t_NP, y_NP, m_N, Y_N = run_models_less(x, times_normal)\n",
    "    \n",
    "    # Define the experimental data for m_N, Y_N, and biomass based on the condition\n",
    "    if condition == 'Normal':\n",
    "        mB_exp = points_normal\n",
    "        mN_exp = points_N_normal\n",
    "        YN_exp = points_YN_normal\n",
    "    elif condition == 'Excess':\n",
    "        mB_exp = points_excess\n",
    "        mN_exp = points_N_excess\n",
    "        YN_exp = points_YN_excess\n",
    "    elif condition == 'Deficit':\n",
    "        mB_exp = points_deficient\n",
    "        mN_exp = points_N_deficient\n",
    "        YN_exp = points_YN_deficient\n",
    "    \n",
    "    w = 2.0\n",
    "    \n",
    "    # Compute relative errors for m_N, Y_N, and biomass\n",
    "    rel_diff_mB = w*np.abs(mB_exp - y_NP.reshape(-1, 1)) / mB_exp\n",
    "    rel_diff_mN = np.abs(mN_exp - m_N.reshape(-1, 1)) / mN_exp\n",
    "    rel_diff_YN = np.abs(YN_exp -  Y_N[1:].reshape(-1, 1)) / YN_exp\n",
    "    \n",
    "    # Combine the relative errors\n",
    "    diff_vec = np.concatenate((rel_diff_mB, rel_diff_mN, rel_diff_YN), axis=0)\n",
    "    \n",
    "    # Compute the overall objective\n",
    "    norm = np.linalg.norm(diff_vec, ord=2)\n",
    "    \n",
    "    # Optional plotting\n",
    "    if print_flag:\n",
    "        # colors = {'Normal': 'red', 'Excess': 'blue', 'Deficit': 'green'}\n",
    "        colors = {'Normal': 'DodgerBlue', 'Excess': 'MidnightBlue', 'Deficit': 'SkyBlue'}\n",
    "        \n",
    "        # Plotting Biomass\n",
    "        plt.figure(dpi=300, figsize=(2, 2))\n",
    "        # plt.plot(t_NP, y_NP, '--', label='NP Model', color=colors[condition])\n",
    "        plt.plot(t_NP, y_NP, '--', label='NP Model', color=np_color)\n",
    "        plt.plot(times_normal, points_normal, 'o', color=md_color)\n",
    "        plt.plot(times_excess, points_excess, 'o', color=hg_color)\n",
    "        plt.plot(times_deficient, points_deficient, 'o', color=lw_color)\n",
    "        plt.xlabel('Time (hr)')\n",
    "        plt.ylabel('Biomass Concentration')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plotting m_N\n",
    "        plt.figure(dpi=300, figsize=(2, 2))\n",
    "        plt.plot(t_NP, m_N, '--', label='m_N Model', color=colors[condition])\n",
    "        plt.plot(times_N_normal, points_N_normal, 'o', color=md_color)\n",
    "        plt.plot(times_N_excess, points_N_excess, 'o', color=hg_color)\n",
    "        plt.plot(times_N_deficient, points_N_deficient, 'o', color=lw_color)\n",
    "        plt.xlabel('Time (hr)')\n",
    "        plt.ylabel('m_N Concentration')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plotting Y_N\n",
    "        plt.figure(dpi=300, figsize=(2, 2))\n",
    "        plt.plot(t_NP[1:], Y_N[1:], '--', label='Y_N Model', color=colors[condition])\n",
    "        plt.plot(times_YN_normal, points_YN_normal, 'o', color=md_color)\n",
    "        plt.plot(times_YN_excess, points_YN_excess, 'o', color=hg_color)\n",
    "        plt.plot(times_YN_deficient, points_YN_deficient, 'o', color=lw_color)\n",
    "        plt.xlabel('Time (hr)')\n",
    "        plt.ylabel('Y_N Value')\n",
    "        plt.legend()\n",
    "    \n",
    "    return norm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73e9ebdd-5420-4a3d-b9ad-4bd1381609a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def objective_experiment(x,print_flag,condition):\n",
    "    \n",
    "    \"\"\"\n",
    "    Similar to the previous objective but\n",
    "    we also pass \"condition\" which is a \n",
    "    str that tells us what data we are trying to fit\n",
    "    \n",
    "    For each condition, we fit different parameters\n",
    "    \"\"\"\n",
    "    t_MEC, y_MEC, t_NP, y_NP, = run_models_less(x,times_normal)\n",
    "    \n",
    "    y_NP = y_NP #*0.9\n",
    "    #print(t_MEC)\n",
    "    if print_flag:\n",
    "        plt.figure(dpi=300,figsize=(2,2))\n",
    "        #plt.plot(t_MEC, y_MEC, label='MEC Model')\n",
    "        if condition=='Normal':\n",
    "            plt.plot(t_NP, y_NP, '--',label='NP Model', color=md_color)\n",
    "        if condition=='Excess':\n",
    "            plt.plot(t_NP, y_NP, '--',label='NP Model', color=hg_color)\n",
    "        if condition=='Deficit':\n",
    "            plt.plot(t_NP, y_NP, '--',label='NP Model', color=lw_color)\n",
    "        #plt.plot(t_MEC, y_MEC, label='MEC Model', color=md_color)\n",
    "\n",
    "        plt.plot(times_normal, points_normal,'o',color=md_color)\n",
    "        plt.plot(times_excess, points_excess,'o',color=hg_color)\n",
    "        plt.plot(times_deficient, points_deficient,'o',color=lw_color)\n",
    "        plt.xlabel('Time (hr)')\n",
    "        plt.ylabel('Biomass Concentration')\n",
    "        plt.legend()\n",
    "    \n",
    "    an = points_normal.T\n",
    "    an = an.reshape(-1,1)\n",
    "    #print(a)\n",
    "    ad = points_deficient.T\n",
    "    ad = ad.reshape(-1,1)\n",
    "    \n",
    "    ae = points_excess.T\n",
    "    ae = ae.reshape(-1,1)\n",
    "   \n",
    "    b = y_NP\n",
    "    #print(b)\n",
    "    rel_diff_normal=np.zeros((len(b),1))\n",
    "    rel_diff_excess=np.zeros((len(b),1))\n",
    "    rel_diff_deficit=np.zeros((len(b),1))\n",
    "    #print(len(b))\n",
    "    #print(rel_diff)\n",
    "    \n",
    "    \n",
    "    for i in range(len(b)):\n",
    "        modifier = 1.0\n",
    "        if i>=4:\n",
    "            modifier = 4.0\n",
    "        rel_diff_normal[i]=modifier*np.abs(an[i]-b[i])/an[i]\n",
    "        rel_diff_excess[i]=modifier*np.abs(ae[i]-b[i])/ae[i]\n",
    "        rel_diff_deficit[i]=modifier*np.abs(ad[i]-b[i])/ad[i]\n",
    "    #the line below was some attempt to fit all of the with a single set of params, ignore\n",
    "    #diff_vec = np.concatenate((rel_diff_normal, rel_diff_excess, rel_diff_deficit), axis=1)\n",
    "    if condition=='Normal':\n",
    "        diff_vec = rel_diff_normal\n",
    "    elif condition == 'Deficit':\n",
    "        diff_vec = rel_diff_deficit\n",
    "    elif condition=='Excess':\n",
    "        diff_vec = rel_diff_excess\n",
    "    #print(rel_diff) \n",
    "    #print(rel_diff[0])\n",
    "    #print(a-b)\n",
    "    norm = np.linalg.norm(diff_vec, ord=2)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416dd345-4178-4451-8c0d-1f23f3cc4746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "objective_experiment(result.x[1:], True,'Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f77bc",
   "metadata": {},
   "source": [
    "### Here starts the fitting to data: Initial guess is the fit we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d0c11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import basinhopping\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "ls = 0.01\n",
    "us = 10.0\n",
    "x0 = result.x[1:] #Start from 1 since we fix mN0\n",
    "#x0 = [0.0017, 0.225, 7.0 ,0.085,38.0, 0.95,0.7]  # initial guess for the decision variables\n",
    "bounds = [(x0[0]*ls,x0[0]*us ), (x0[1]*ls,x0[1]*us ), ((x0[2]*ls,x0[2]*us )),\n",
    "          (x0[3]*ls,x0[3]*us ),(x0[4]*ls,x0[4]*us ),(x0[5]*ls,x0[5]*us ),\n",
    "         (x0[6]*0.8,x0[6]*1.2 )]  # bounds on the decision variables\n",
    "#options = {'disp': True}\n",
    "#result_normal = minimize(objective_experiment, x0,  method='TNC',args=(False,'Normal') , bounds=bounds, options=options)\n",
    "result_normal = differential_evolution(objective_experiment, bounds, args=(False, 'Normal'), maxiter=1000, popsize=15, disp=True)\n",
    "objective_experiment(result_normal.x,True,\"Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c60723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "#ls = 0.01\n",
    "#us = 10.0\n",
    "ls = 0.2\n",
    "us = 5.0\n",
    "#x0 = result.x[1:] #Start from 1 since we fix mN0\n",
    "x0 = result_normal.x\n",
    "#x0 = [0.0017, 0.225, 7.0 ,0.085,38.0, 0.95,0.7]  # initial guess for the decision variables\n",
    "bounds = [(x0[0]*ls,x0[0]*us ), (x0[1]*ls,x0[1]*us ), ((x0[2]*ls,x0[2]*us )),\n",
    "          (x0[3]*ls,x0[3]*us ),(x0[4]*ls,x0[4]*us ),(x0[5]*ls,x0[5]*us ),\n",
    "         (x0[6]*0.8,x0[6]*1.3 )]  # bounds on the decision variables\n",
    "options = {'disp': True}\n",
    "#result_excess = minimize(objective_experiment, x0, args=(False,'Excess') , bounds=bounds, options=options)\n",
    "result_excess = differential_evolution(objective_experiment, bounds, args=(False, 'Excess'), maxiter=1000, popsize=15, disp=True)\n",
    "\n",
    "objective_experiment(result_excess.x,True,\"Excess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d7605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "#ls = 0.01\n",
    "#us = 10.0\n",
    "ls = 0.2\n",
    "us = 5.0\n",
    "#x0 = result.x[1:] #Start from 1 since we fix mN0\n",
    "x0 = result_normal.x\n",
    "#x0 = [0.0017, 0.225, 7.0 ,0.085,38.0, 0.95,0.7]  # initial guess for the decision variables\n",
    "bounds = [(x0[0]*ls,x0[0]*us ), (x0[1]*ls,x0[1]*us ), ((x0[2]*ls,x0[2]*us )),\n",
    "          (x0[3]*ls,x0[3]*us ),(x0[4]*ls,x0[4]*us ),(x0[5]*ls,x0[5]*us ),\n",
    "         (x0[6]*0.8,x0[6]*1.3 )]  # bounds on the decision variables\n",
    "options = {'disp': True}\n",
    "#result_excess = minimize(objective_experiment, x0, args=(False,'Excess') , bounds=bounds, options=options)\n",
    "result_deficit = differential_evolution(objective_experiment, bounds, args=(False, 'Deficit'), maxiter=1000, popsize=15, disp=True)\n",
    "\n",
    "objective_experiment(result_deficit.x,True,\"Deficit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b0ff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_experiment(result.x, result_normal.x,result_excess.x,result_deficit.x,True)\n",
    "plt.show()\n",
    "#Same colors as before, dashed line is MEC model for normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a099cc",
   "metadata": {},
   "source": [
    "### Now, let's gather all variables into a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1634b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_deficit.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_excess.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_normal.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df63b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = np.column_stack((result.x[1:], result_normal.x, result_excess.x, result_deficit.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859167d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e776f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2349af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the min and max value from the optimization variables to \n",
    "#get bounds for sensitivities\n",
    "min_values = np.min(all_params, axis=1)\n",
    "max_values = np.max(all_params, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.column_stack((min_values, max_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f28d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random samples of x within the bounds\n",
    "num_samples = 2000\n",
    "x = np.zeros((num_samples,bounds.shape[0]))\n",
    "for i in range(bounds.shape[0]):\n",
    "    x[:, i] = np.random.uniform(low=bounds[i, 0], high=bounds[i, 1], size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape\n",
    "f_vals = np.zeros((num_samples,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aba6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that yields the quantitity whose sensitivity we're \n",
    "# studying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7fafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_sens(x,k):\n",
    "    \"\"\"\n",
    "    For each parameter x, \n",
    "    get an integral of the curve over time\n",
    "    This is a representative scalar quantity\n",
    "    that reflects how the parameters x affect the dynamics \n",
    "    in an average sense\n",
    "    \"\"\"\n",
    "    tspan = np.arange(0, 30.05, 0.05)\n",
    "    t_MEC, y_MEC, t_NP, y_NP, _, _ = run_models_less(x,tspan)\n",
    "    integral = np.trapz(y_NP, t_NP)\n",
    "    #plt.plot(t_NP,y_NP,'-',alpha=k/10,linewidth=5)\n",
    "    return integral   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_vals = np.zeros((num_samples,1))\n",
    "for k in range(num_samples):\n",
    "    #print(x[k,:])\n",
    "    f_vals[k,0] = f_sens(x[k,:],k)\n",
    "    #print(f_vals[k,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c35b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(f_vals)\n",
    "benchmark_val = 0.5*np.median(f_vals) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37968315",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_vals_modified = f_vals - benchmark_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6dcca5",
   "metadata": {},
   "source": [
    "### Issue: A lot of parameter combinations lead to unphysical predictions\n",
    "To help generate only physical predictions, we can build a classifier that \n",
    "can predict whether the prediction will be >0 or <0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706189b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "Yc = np.sign(f_vals_modified);\n",
    "y_binary = np.where(Yc==1,1,0)\n",
    "x_binary = x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d68422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_binary, y_binary, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defaed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52625fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801995f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b08c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=x0.shape[0], activation='tanh'))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0117b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict Y for new X\n",
    "predicted_Y = np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d2622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find error of classifier \n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# Y_test and predicted_Y are the actual and predicted outputs, respectively\n",
    "acc = accuracy_score(Y_test, predicted_Y)\n",
    "f1 = f1_score(Y_test, predicted_Y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have the classifier, let's get good samples for SA.\n",
    "# Generate new random samples of x within the bounds\n",
    "num_samples = int(10e5)\n",
    "xs = np.zeros((num_samples,bounds.shape[0]))\n",
    "for i in range(bounds.shape[0]):\n",
    "    xs[:, i] = np.random.uniform(low=bounds[i, 0], high=bounds[i, 1], size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33551081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's pass them through the classifier and predict whether they will yield \n",
    "#a physically meaningful or not prediction. \n",
    "# We want all classifier values with 1 (which means positive)\n",
    "predicted_ys =model.predict(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69294687",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_indices = [i for i in range(len(predicted_ys)) if predicted_ys[i] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b9076",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positive_indices)/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positive_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f6570",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobol_samples = len(positive_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40588632",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsobol = 20000 #Sobol analysis samples - must be at max equal to 'sobol_samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165320e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsobol = xs[positive_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f11570",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsobol = xsobol[0:Nsobol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a374d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ded32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsobol = np.zeros((Nsobol,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388dd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e426d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(Nsobol):\n",
    "    #print(x[k,:])\n",
    "    fsobol[k,0] = f_sens(xsobol[k,:],k)\n",
    "    #print(f_vals[k,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546be998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But we're not done, due to inaccuracy of the classifier not all predicted \n",
    "# integrals will be positive. We need to keep only the positive.\n",
    "# The classifier helped get samples that are more likely to give positive \n",
    "# values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(fsobol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "medfv = np.median(f_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1d2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sobol = np.where(fsobol > medfv )[0]\n",
    "xsobol_adjusted = xsobol[positive_sobol]\n",
    "fsobol_adjusted = fsobol[positive_sobol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ec4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sobol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a662514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io as  sio\n",
    "sio.savemat(mat_out_path + 'lettuce_exp_matrices.mat', {'matrix1': xsobol_adjusted, 'matrix2': fsobol_adjusted})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c67b3",
   "metadata": {},
   "source": [
    "## Stop here and run the sensitivity analysis on matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b60817",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sens_indices = scipy.io.loadmat(mat_out_path + 'lettuce_exp_sensitivity_results.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9951052",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_indices = sens_indices['sensitivities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef502ad-bf34-42f3-9dc1-e0c78c2a40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list of labels for the plot\n",
    "# labels = ['$x_0$', '$x_1$', '$x_2$', '$x_3$', '$x_4$', '$x_5$', '$x_6$']\n",
    "\n",
    "# # Create the bar plot with black border\n",
    "# fig, ax = plt.subplots(dpi=500)\n",
    "# ax.barh(labels, sensitivity_indices[:, 0], edgecolor='black')\n",
    "\n",
    "# # Add labels to the plot\n",
    "# ax.set_xlabel('Sensitivity Index Value')\n",
    "# #ax.set_title('Sensitivity Indices')\n",
    "# ax.set_ylabel('Variable')\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n",
    "# Create a list of labels for the plot\n",
    "# labels = ['$x_0$', '$x_1$', '$x_2$', '$x_3$', '$x_4$', '$x_5$', '$x_6$']\n",
    "labels = ['$r$', '$K$', r'$\\alpha$', r'$\\eta_\\text{N} (b)$', r'$\\eta_\\text{N} (m)$', r'$\\mu_\\text{N} (b)$', r'$\\mu_\\text{N} (m)$']\n",
    "\n",
    "# Create the bar plot with black border\n",
    "fig, ax = plt.subplots(figsize=(2,2))\n",
    "ax.barh(labels, sensitivity_indices[:, 0], edgecolor='black')\n",
    "\n",
    "# Add labels to the plot\n",
    "ax.set_xlabel('Sensitivity Index Value')\n",
    "#ax.set_title('Sensitivity Indices')\n",
    "ax.set_ylabel('Parameter')\n",
    "\n",
    "ax.xaxis.set_major_locator(MultipleLocator(0.05))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(0.025))\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.savefig(out_path + \"lettuce_exp-sensitivity.png\", bbox_inches='tight', transparent=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e55c86-40c2-4553-81cb-338f501b223d",
   "metadata": {},
   "source": [
    "## Generate and plot hybrid MEC-NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = 30\n",
    "t_length = np.arange(0, t_end, 1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"regime\"] = [\"lw\",\"md\",\"hi\"]\n",
    "\n",
    "# t_MECn, y_MECn, t_NPn, y_NPn = run_models_less(result_normal.x,np.arange(0, t_end+1, 1))\n",
    "# t_MECe, y_MECe, t_NPe, y_NPe = run_models_less(result_excess.x,np.arange(0, t_end+1, 1))\n",
    "\n",
    "result_lw = run_models_less((result_deficit.x),t_length)\n",
    "result_md = run_models_less((result_normal.x),t_length)\n",
    "result_hi = run_models_less((result_excess.x),t_length)\n",
    "\n",
    "df[\"tMEC\"] = [result_lw[0], result_md[0], result_hi[0]]\n",
    "df[\"yMEC\"] = [result_lw[1], result_md[1], result_hi[1]]\n",
    "df[\"tNP\"] = [result_lw[2], result_md[2], result_hi[2]]\n",
    "df[\"yNP\"] = [result_lw[3], result_md[3], result_hi[3]]\n",
    "df[\"yNP\"] *= 1.5\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "df2[\"cond\"] = [\"lw\",\"md\",\"hi\"]\n",
    "df2[\"time\"] = [result_lw[0]+1, result_md[0]+1, result_hi[0]+1]\n",
    "df2[\"hybrid_curve\"] = [[],[],[]]\n",
    "\n",
    "for regime in range(0,3):\n",
    "    hyb_crv = [0 for i in range(0,t_end)]\n",
    "    for t in range(0,t_end):\n",
    "        if df.iloc[1,2][t] > df.iloc[regime,4][t]:  # we have only to MEC-Normal\n",
    "            hyb_crv[t] = df.iloc[regime,4][t]\n",
    "        else:\n",
    "            hyb_crv[t] = df.iloc[regime,2][t]\n",
    "    df2.at[regime, \"hybrid_curve\"] = hyb_crv\n",
    "    \n",
    "clr_hybrid = ['k','k','k']\n",
    "lbl_hybrid = [\"Deficienct\",\"Normal\",\"Excess\"]\n",
    "fig_hybrid, ax_hybrid = plt.subplots(figsize=(1.5,2.625))\n",
    "hybird_args = {'alpha': 1, 'lw': 2.5, 'dashes':[2.5, 1]}\n",
    "regime = 1  # {0,1,2} |-> {low, med, high}\n",
    "\n",
    "ax_hybrid.plot(df2.iloc[regime,1],df2.iloc[regime,2],c=\"red\", label=\"Hybrid\", zorder=99, alpha=1, lw=1)\n",
    "ax_hybrid.plot(df.iloc[regime,1]+1,df.iloc[regime,2],c='LimeGreen', ls=\"--\", label=\"MEC\", **hybird_args)\n",
    "ax_hybrid.plot(df.iloc[regime,3]+1,df.iloc[regime,4],c='DodgerBlue', ls=\"--\", label=\"NP\", **hybird_args)\n",
    "\n",
    "from matplotlib.ticker import (MultipleLocator)\n",
    "ax_hybrid.xaxis.set_major_locator(MultipleLocator(10))\n",
    "ax_hybrid.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "ax_hybrid.yaxis.set_major_locator(MultipleLocator(20))\n",
    "ax_hybrid.yaxis.set_minor_locator(MultipleLocator(10))\n",
    "ax_hybrid.set_xlabel(r'$t [\\si{\\day\\of{AE}}]$')\n",
    "ax_hybrid.set_ylabel(r'$\\invbreve{m}_\\text{T}\\ [\\si{\\gram\\of{DW}\\per\\meter\\squared}]$')\n",
    "\n",
    "# y0 = df.iloc[regime,4]\n",
    "# y1 = df.iloc[regime,2]\n",
    "# ax_hybrid.fill_between(t_length+1,y0,y1,color='pink',alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(out_path + \"MEC-NP_hybrid.png\", bbox_inches='tight', transparent=True, dpi=2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd589c74",
   "metadata": {},
   "source": [
    "## Draft Code Below this point\n",
    "I tried to compare the prior/posterior distributions but nothing interesting really"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9152c58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xsobol_adjusted.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d94c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee372b00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = xsobol_adjusted.shape[0]\n",
    "# Generate N samples for each variable\n",
    "samples = np.zeros((N, 7))\n",
    "for i in range(7):\n",
    "    samples[:, i] = np.random.uniform(bounds[i, 0], bounds[i, 1], size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a841e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsobol_adjusted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnum=50\n",
    "for k in range(samples.shape[1]):\n",
    "    plt.figure(dpi=100,figsize=(2,2))\n",
    "    plt.hist(samples[:,k],bins=binnum,alpha=0.6,color='red',density=True)\n",
    "\n",
    "    plt.hist(xsobol_adjusted[:,k],bins=binnum,alpha=0.5, color=hg_color,density=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48abd62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39aec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the range of each variable\n",
    "range_ = bounds[:, 1] - bounds[:, 0]\n",
    "\n",
    "# calculate the mean value of each variable\n",
    "mean_ = np.mean(bounds, axis=1)\n",
    "\n",
    "# calculate the upper bound value of each variable\n",
    "upper_ = bounds[:, 1]\n",
    "\n",
    "# normalize the range by the mean value\n",
    "relative_change_mean = range_ / mean_\n",
    "\n",
    "# normalize the range by the upper bound value\n",
    "relative_change_upper = range_ / upper_\n",
    "\n",
    "# print the normalized range\n",
    "for i in range(len(relative_change_mean)):\n",
    "    print(f\"Variable {i+1}: Relative change (mean) = {relative_change_mean[i]:.2%}, Relative change (upper) = {relative_change_upper[i]:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
